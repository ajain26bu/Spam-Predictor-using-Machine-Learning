{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "## course: CS571\n",
    "## date: 12/5/2017\n",
    "## Authors : Siddharth Kulshrestha, Sahil Kolwankar, Alankrit Jain, Pooja Upadhyay, Sachin Rodge\n",
    "## Project: SMS Spam Predictor using Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Required Packages\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report,confusion_matrix, f1_score, accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, GridSearchCV, train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import wordcloud\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7faa781a6ad0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(30,20))\n",
    "pd.set_option('display.max_colwidth', 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_display(filename):\n",
    "    df = pd.read_csv(filename,sep = \"\\t\")\n",
    "    print \"Data Read Successfully \\n\"\n",
    "    print df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Read Successfully \n",
      "\n",
      "  class                           text\n",
      "0   ham  Go until jurong point, cra...\n",
      "1   ham  Ok lar... Joking wif u oni...\n",
      "2  spam  Free entry in 2 a wkly com...\n",
      "3   ham  U dun say so early hor... ...\n",
      "4   ham  Nah I don't think he goes ...\n",
      "5  spam  FreeMsg Hey there darling ...\n",
      "6   ham  Even my brother is not lik...\n",
      "7   ham  As per your request 'Melle...\n",
      "8  spam  WINNER!! As a valued netwo...\n",
      "9  spam  Had your mobile 11 months ...\n"
     ]
    }
   ],
   "source": [
    "read_and_display(\"SMSSpamCollection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Executing the Haskell DataClearning program\n",
    "os.system('ghc Data_Cleanse_PL.hs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Read Successfully \n",
      "\n",
      "  class                           text\n",
      "0   ham  go until jurong point craz...\n",
      "1   ham        ok lar joking wif u oni\n",
      "2  spam  free entry in 2 a wkly com...\n",
      "3   ham  u dun say so early hor u c...\n",
      "4   ham  nah i don't think he goes ...\n",
      "5  spam  freemsg hey there darling ...\n",
      "6   ham  even my brother is not lik...\n",
      "7   ham  as per your request 'melle...\n",
      "8  spam  winner as a valued network...\n",
      "9  spam  had your mobile 11 months ...\n"
     ]
    }
   ],
   "source": [
    "read_and_display(\"out.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming_text_file(filename):\n",
    "    '''\n",
    "    This function is used to Apply a Stemming method i.e Porter Stemmer on the text file.\n",
    "    Stemming is a process to normalize similiar, slightly different words into same words.\n",
    "    '''\n",
    "    with open(filename, 'r+') as f:\n",
    "        for line in f:\n",
    "            singles = []\n",
    "\n",
    "            stemmer = PorterStemmer() \n",
    "            for plural in line.split():\n",
    "                singles.append(stemmer.stem(plural))\n",
    "        f.seek(0)\n",
    "        print ' '.join(singles)\n",
    "        f.write(' '.join(singles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_wordcloud(column_name):\n",
    "    '''\n",
    "    Returns a Wordcloud for Exploratory Dataset\n",
    "    '''\n",
    "    wordcloud = wordcloud.WordCloud().generate(' '.join(df['text']))\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Spam_Filter_Model(object):\n",
    "    \n",
    "    text_test, text_train, class_test, class_train, data_matrix, classifier = (None, None, None, None, None, None)\n",
    "    \n",
    "    def train_test_split(self, test_split_percent):\n",
    "        '''\n",
    "        This method takes a argument : test_split_percent and splits the dataset into training \n",
    "        and testing according to the specified percentage\n",
    "        '''\n",
    "        \n",
    "        assert test_split_percent <= 0.25, \"Please reduce the size of the training set \\n\"\n",
    "        \n",
    "        self.text_train, self.text_test, self.class_train, self.class_test = \\\n",
    "        train_test_split(self.dataset.text, self.dataset[\"class\"], test_size = test_split_percent)\n",
    "        \n",
    "        \n",
    "    def __init__(self, algorithm, dataset, vectorize, test_split_percent):\n",
    "        \n",
    "        self.algorithm = algorithm\n",
    "        self.dataset = pd.read_csv(dataset, sep = \"\\t\")\n",
    "        self.vectorize = vectorize\n",
    "        self.train_test_split(test_split_percent)\n",
    "               \n",
    "    def show_data(self):\n",
    "        \"\"\"\n",
    "        Return the first five rows of the dataset\n",
    "        \"\"\"\n",
    "        print self.dataset.head(5)\n",
    "        \n",
    "    def show_shape(self):\n",
    "        \"\"\"\n",
    "        Prints out the number of Examples and number of classes in the dataset\n",
    "        \"\"\"\n",
    "        print \"The shape of the dataset is \\n\"\n",
    "        print \"Number of Examples - \", str(self.dataset.shape[0]), \"\\n\"\n",
    "        print \"Number of Classes - \", str(self.dataset.shape[1]), \"\\n\"\n",
    "                \n",
    "    def describe_data(self):\n",
    "        \"\"\"\n",
    "        Returns the description of the dataset and its important attributes\n",
    "        \"\"\"\n",
    "        return self.dataset.groupby('class').describe()\n",
    "                \n",
    "            \n",
    "    def word_count_visualize(self):\n",
    "        '''\n",
    "        Returns a histogram with the size of each datapoint\n",
    "        '''\n",
    "        word_count_list = []\n",
    "        counter = Counter(self.dataset[\"text\"])\n",
    "        for index, row in self.dataset.iterrows():\n",
    "            word_count_list.append(len(re.findall(r'\\w+', row[\"text\"])))\n",
    "        hist = plt.hist(word_count_list, alpha = 0.5)\n",
    "        plt.show()\n",
    "        \n",
    "    def vectorize_train_test(self):\n",
    "        '''\n",
    "        This method vectorizes and trains the the training set using the specified Machine Learning\n",
    "        Algorithm and tests the result with the training set\n",
    "        '''\n",
    "        count_vectorizer = CountVectorizer()\n",
    "        counts = count_vectorizer.fit_transform(self.text_train)\n",
    "        count1 = count_vectorizer.transform(self.text_test)\n",
    "        \n",
    "        tfidf = self.vectorize()\n",
    "        tf_mat = tfidf.fit_transform(counts)\n",
    "        tf_mat_test = tfidf.transform(count1)\n",
    "        \n",
    "        classifier = self.algorithm()\n",
    "\n",
    "        targets = self.class_train\n",
    "        classifier.fit(tf_mat, targets)\n",
    "        self.classifier = classifier\n",
    "        \n",
    "        preds = classifier.predict(tf_mat_test)\n",
    "        print 'Accuracy of the test set is: ', accuracy_score(self.class_test, preds) * 100 ,\"%\" \"\\n \\n\"\n",
    "        \n",
    "        return preds\n",
    "        \n",
    "\n",
    "    def metrics(self, preds):\n",
    "        '''\n",
    "        Returns essential metrics to study the classification results and help user choose the better algorithm\n",
    "        '''\n",
    "        print \"The confusion Matrix is \\n\" \n",
    "        cm = confusion_matrix(self.class_test, preds)\n",
    "        print cm, \"\\n\"\n",
    "        print \"The classification report is: \\n\"\n",
    "        print classification_report(self.class_test, preds)\n",
    "        print \"\\n\"\n",
    "        \n",
    "        TP = cm[0][0]\n",
    "        FP = cm[0][1]\n",
    "        FN = cm[1][0]\n",
    "        TN = cm[1][1]\n",
    "\n",
    "        specificity = (float(TN)/float(TN+FP))\n",
    "        print \"The specificity is \", str(specificity * 100), \"%\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>4825</td>\n",
       "      <td>4516</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>747</td>\n",
       "      <td>653</td>\n",
       "      <td>Please call our customer service representativ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       text                                                               \n",
       "      count unique                                                top freq\n",
       "class                                                                     \n",
       "ham    4825   4516                             Sorry, I'll call later   30\n",
       "spam    747    653  Please call our customer service representativ...    4"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.describe_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the test set is:  97.2197309417 %\n",
      " \n",
      "\n",
      "The confusion Matrix is \n",
      "\n",
      "[[966   4]\n",
      " [ 27 118]] \n",
      "\n",
      "The classification report is: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        ham       0.97      1.00      0.98       970\n",
      "       spam       0.97      0.81      0.88       145\n",
      "\n",
      "avg / total       0.97      0.97      0.97      1115\n",
      "\n",
      "\n",
      "\n",
      "The specificity is  96.7213114754 %\n"
     ]
    }
   ],
   "source": [
    "model1 = Spam_Filter_Model(LogisticRegression, \"SMSSpamCollection\", TfidfTransformer, 0.2)\n",
    "log_reg = model1.vectorize_train_test()\n",
    "\n",
    "model1.metrics(log_reg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the test set is:  97.130044843 %\n",
      " \n",
      "\n",
      "The confusion Matrix is \n",
      "\n",
      "[[957   1]\n",
      " [ 31 126]] \n",
      "\n",
      "The classification report is: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        ham       0.97      1.00      0.98       958\n",
      "       spam       0.99      0.80      0.89       157\n",
      "\n",
      "avg / total       0.97      0.97      0.97      1115\n",
      "\n",
      "\n",
      "\n",
      "The specificity is  99.2125984252 %\n"
     ]
    }
   ],
   "source": [
    "model2 = Spam_Filter_Model(RandomForestClassifier, \"SMSSpamCollection\", TfidfTransformer, 0.2)\n",
    "random_forest_model = model2.vectorize_train_test()\n",
    "model2.metrics(random_forest_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the test set is:  97.2197309417 %\n",
      " \n",
      "\n",
      "The confusion Matrix is \n",
      "\n",
      "[[948   2]\n",
      " [ 29 136]] \n",
      "\n",
      "The classification report is: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        ham       0.97      1.00      0.98       950\n",
      "       spam       0.99      0.82      0.90       165\n",
      "\n",
      "avg / total       0.97      0.97      0.97      1115\n",
      "\n",
      "\n",
      "\n",
      "The specificity is  98.5507246377 %\n"
     ]
    }
   ],
   "source": [
    "model3 = Spam_Filter_Model(ExtraTreesClassifier, \"SMSSpamCollection\", TfidfTransformer, 0.2)\n",
    "extra_tree_model = model3.vectorize_train_test()\n",
    "model3.metrics(extra_tree_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "[Errno 98] Address already in use",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-601e18c7f1b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m   \u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/siddharth/anaconda2/lib/python2.7/site-packages/flask/app.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, host, port, debug, **options)\u001b[0m\n\u001b[1;32m    839\u001b[0m         \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'use_debugger'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0mrun_simple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m             \u001b[0;31m# reset the first request information if the development server\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/siddharth/anaconda2/lib/python2.7/site-packages/werkzeug/serving.pyc\u001b[0m in \u001b[0;36mrun_simple\u001b[0;34m(hostname, port, application, use_reloader, use_debugger, use_evalex, extra_files, reloader_interval, reloader_type, threaded, processes, request_handler, static_files, passthrough_errors, ssl_context)\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maddress_family\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSOCK_STREAM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m             \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetsockopt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSOL_SOCKET\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSO_REUSEADDR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 720\u001b[0;31m             \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhostname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    721\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'set_inheritable'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m                 \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_inheritable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/siddharth/anaconda2/lib/python2.7/socket.pyc\u001b[0m in \u001b[0;36mmeth\u001b[0;34m(name, self, *args)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_m\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_socketmethods\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: [Errno 98] Address already in use"
     ]
    }
   ],
   "source": [
    "from flask import Flask, render_template\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "  return render_template('template.html')\n",
    "\n",
    "@app.route('/my-link/')\n",
    "def my_link():\n",
    "  print 'I got clicked!'\n",
    "\n",
    "  return 'Click.'\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  app.run(debug=True)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
